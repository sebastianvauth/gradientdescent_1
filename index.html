<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Introduction to Gradient Descent - Why and What?</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background-color: #ffffff;
            font-size: 150%;
        }
        section {
            margin-bottom: 20px;
            padding: 20px;
            background-color: #ffffff;
            display: none;
            opacity: 0;
            transition: opacity 0.5s ease-in;
        }
        h1, h2, h3, h4 {
            color: #333;
            margin-top: 20px;
        }
        p, li {
            line-height: 1.6;
            color: #444;
            margin-bottom: 20px;
        }
        ul {
            padding-left: 20px;
        }
        .image-placeholder, .interactive-placeholder, .continue-button, .vocab-section, .why-it-matters, .test-your-knowledge, .faq-section, .stop-and-think {
            text-align: left;
        }
        .image-placeholder img, .interactive-placeholder img {
            max-width: 100%;
            height: auto;
            border-radius: 5px;
        }
        .vocab-section, .why-it-matters, .test-your-knowledge, .faq-section, .stop-and-think {
            padding: 20px;
            border-radius: 8px;
            margin-top: 20px;
        }
        .vocab-section {
            background-color: #f0f8ff;
        }
        .vocab-section h3 {
            color: #1e90ff;
            font-size: 0.75em;
            margin-bottom: 5px;
            margin-top: 5px;
        }
        .vocab-section h4 {
            color: #000;
            font-size: 0.9em;
            margin-top: 10px;
            margin-bottom: 8px;
        }
        .vocab-term {
            font-weight: bold;
            color: #1e90ff;
        }
        .why-it-matters {
            background-color: #ffe6f0;
        }
        .why-it-matters h3 {
            color: #d81b60;
            font-size: 0.75em;
            margin-bottom: 5px;
            margin-top: 5px;
        }
        .stop-and-think {
            background-color: #e6e6ff;
        }
        .stop-and-think h3 {
            color: #4b0082;
            font-size: 0.75em;
            margin-bottom: 5px;
            margin-top: 5px;
        }
        .continue-button {
            display: inline-block;
            padding: 10px 20px;
            margin-top: 15px;
            color: #ffffff;
            background-color: #007bff;
            border-radius: 5px;
            text-decoration: none;
            cursor: pointer;
        }
        .reveal-button {
            display: inline-block;
            padding: 10px 20px;
            margin-top: 15px;
            color: #ffffff;
            background-color: #4b0082;
            border-radius: 5px;
            text-decoration: none;
            cursor: pointer;
        }
        .test-your-knowledge {
            background-color: #e6ffe6;
        }
        .test-your-knowledge h3 {
            color: #28a745;
            font-size: 0.75em;
            margin-bottom: 5px;
            margin-top: 5px;
        }
        .test-your-knowledge h4 {
            color: #000;
            font-size: 0.9em;
            margin-top: 10px;
            margin-bottom: 8px;
        }
        .test-your-knowledge p {
            margin-bottom: 15px;
        }
        .check-button {
            display: inline-block;
            padding: 10px 20px;
            margin-top: 15px;
            color: #ffffff;
            background-color: #28a745;
            border-radius: 5px;
            text-decoration: none;
            cursor: pointer;
            border: none;
            font-size: 1em;
        }
        .faq-section {
            background-color: #fffbea;
        }
        .faq-section h3 {
            color: #ffcc00;
            font-size: 0.75em;
            margin-bottom: 5px;
            margin-top: 5px;
        }
        .faq-section h4 {
            color: #000;
            font-size: 0.9em;
            margin-top: 10px;
            margin-bottom: 8px;
        }
    </style>
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
</head>
<body>
    <section id="section1">
<div class="image-placeholder">
            <img src="images//an-illustration-of-a-person-hiking-down.jpeg
?height=300&width=600" alt="Image showing a person hiking down a gently sloping hill with a clear path leading to a valley, symbolizing the step-by-step approach of gradient descent towards finding the minimum.">
        </div>
        <h1>Introduction to Gradient Descent - Why and What?</h1>
        <p>Ever wondered how machines learn to make smart decisions? A big part of that magic lies in something called <strong>Gradient Descent</strong>. Think of it as the secret ingredient behind many powerful algorithms. In this first lesson, we'll understand why Gradient Descent is so important and what it's all about. No complex code or scary math just yet – we'll start with the core concepts. Ready to explore?</p>
        <div class="continue-button" onclick="showNextSection(2)">Continue</div>
    </section>

    <section id="section2">
        <h2>The Optimization Challenge</h2>
        <p>Imagine you're trying to find the lowest point in a valley. You can't see the whole valley at once, you're just standing somewhere on the slope.</p>
        <div class="continue-button" onclick="showNextSection(3)">Continue</div>
    </section>

    <section id="section3">
        <p>In Machine Learning, we face a similar challenge! We want to find the 'lowest point' of something called a <strong>cost function</strong>. This cost function measures how well our model is performing – the lower the cost, the better our model.</p>
        <div class="continue-button" onclick="showNextSection(4)">Continue</div>
    </section>

    <section id="section4">
        <p>Think of the cost function as the landscape of our valley. Our goal is to adjust our model's <strong>parameters</strong> (think of them as your hiking boots and poles) to reach the bottom of this valley, where the cost is minimized and our model performs its best.</p>
        <div class="image-placeholder">
            <img src="images/a-3d-illustration-of-a-landscape.jpeg?height=300&width=600" alt="Image showing a 3D landscape with hills and valleys, with a red ball at a high point, symbolizing the initial parameters and the cost function landscape.">
        </div>
        <div class="continue-button" onclick="showNextSection(5)">Continue</div>
    </section>

    <section id="section5">
        <p>But here's the catch: these 'valleys' can be vast and complex, especially with lots of data and intricate models. Trying to find the absolute lowest point directly can be incredibly difficult and time-consuming, especially when dealing with huge datasets. That's where Gradient Descent steps in as our clever guide!</p>
        <div class="continue-button" onclick="showNextSection(6)">Continue</div>
    </section>

    <section id="section6">
        <p>Gradient Descent is like a smart hiker who always takes steps in the direction that goes downhill the fastest. It's an <strong>iterative optimization algorithm</strong> – meaning it takes steps, refines its position, and repeats until it (hopefully!) reaches the bottom of the valley, or at least gets very close.</p>
        <div class="interactive-placeholder">
            <img src="/placeholder.svg?height=300&width=600" alt="Animation of a hiker taking small steps downhill on a curved surface, gradually moving towards the lowest point, illustrating the iterative process of gradient descent.">
        </div>
        <div class="continue-button" onclick="showNextSection(7)">Continue</div>
    </section>

    <section id="section7">
        <p>So, instead of trying to jump directly to the bottom, Gradient Descent takes a series of smaller, smarter steps. This step-by-step approach makes it much more practical and efficient for finding good solutions, even in complex scenarios.</p>
        <div class="vocab-section">
            <h3>Build Your Vocab</h3>
            <h4 class="vocab-term">Optimization Algorithm</h4>
            <p>An algorithm designed to find the best possible solution (e.g., minimum or maximum) to a problem, often by iteratively adjusting variables.</p>
        </div>
        <p>And that, in a nutshell, is why we use Gradient Descent in Machine Learning!</p>
        <div class="continue-button" onclick="showNextSection(8)">Continue</div>
    </section>

    <section id="section8">
        <h2>The Core Idea: Stepping Downhill</h2>
        <p>Let's get a bit more specific about how this 'smart hiker' (Gradient Descent) works. Imagine our cost function as a simple curve, like a bowl shape.</p>
        <div class="continue-button" onclick="showNextSection(9)">Continue</div>
    </section>

    <section id="section9">
        <p>We start by choosing a <strong>random starting point</strong> on this curve. This is our initial guess for the model's parameters – let's call it \(\beta_{start}\).</p>
        <div class="visualaid-placeholder">
            <img src="/placeholder.svg?height=300&width=600" alt="Graph of a simple U-shaped curve (f(x)=x²) representing a cost function, with a point marked 'β_start' on the curve, away from the bottom.">
        </div>
        <div class="continue-button" onclick="showNextSection(10)">Continue</div>
    </section>

    <section id="section10">
        <p>Now, we need to figure out which way is 'downhill'. In math terms, 'downhill' is the direction of the <strong>negative gradient</strong> of our cost function. The gradient itself, denoted as \(\nabla_{\beta}C(\beta)\), points in the direction of the steepest <em>increase</em> (uphill). So, to go downhill, we go in the <em>opposite</em> direction, \(-\nabla_{\beta}C(\beta)\).</p>
        <div class="continue-button" onclick="showNextSection(11)">Continue</div>
    </section>

    <section id="section11">
        <p>Think of the gradient as a compass that always points uphill. Gradient Descent uses this 'compass' to take a step in the opposite direction, moving us towards the minimum point of the cost function.</p>
        <div class="image-placeholder">
            <img src="/placeholder.svg?height=300&width=600" alt="Image showing a compass pointing uphill on a slope, with an arrow indicating the direction of negative gradient (downhill).">
        </div>
        <div class="continue-button" onclick="showNextSection(12)">Continue</div>
    </section>

    <section id="section12">
        <p>The size of each step we take is controlled by something called the <strong>learning rate</strong>, denoted by \(\alpha\). A larger learning rate means bigger steps, and a smaller learning rate means smaller, more cautious steps.</p>
        <div class="continue-button" onclick="showNextSection(13)">Continue</div>
    </section>

    <section id="section13">
        <p>So, in each step of Gradient Descent, we update our parameters \(\beta\) using the following rule:</p>
        <div class="continue-button" onclick="showNextSection(14)">Continue</div>
    </section>

    <section id="section14">
        <p>\[\beta_{new} = \beta_{old} - \alpha \nabla_{\beta}C(\beta_{old})\]</p>
        <p>Let's break down this formula:</p>
        <div class="continue-button" onclick="showNextSection(15)">Continue</div>
    </section>

    <section id="section15">
        <ul>
            <li>\(\beta_{new}\): This is the updated value of our parameters after one step.</li>
            <li>\(\beta_{old}\): This is the current value of our parameters before the update.</li>
            <li>\(\alpha\): This is the <strong>learning rate</strong>. It's a small positive number that determines the step size. We need to choose this carefully – too big and we might overshoot the minimum, too small and it might take forever to get there!</li>
            <li>\(\nabla_{\beta}C(\beta_{old})\): This is the <strong>gradient</strong> of the cost function \(C(\beta)\) calculated at the current parameter values \(\beta_{old}\). It tells us the direction of steepest ascent at our current position.</li>
        </ul>
        <p>We repeat this update step over and over again, iteratively moving closer and closer to the minimum of the cost function. We continue this process until we 'converge', meaning the cost function stops decreasing significantly, or we reach a pre-defined number of steps.</p>
        <div id="interactive-container" style="margin: 20px auto; width: 680px; background-color: #f5f5f5; border-radius: 10px; padding: 20px; text-align: center;">
  <canvas id="gdCanvas" width="600" height="400" style="border:1px solid #ccc; cursor: pointer; border-radius: 5px;"></canvas>
  <br>
  <label for="lrSlider" style="font-size:16px;">
    Learning Rate (α): <span id="lrValue">0.05</span>
  </label>
  <input type="range" id="lrSlider" min="0.001" max="1" step="0.001" value="0.05" style="vertical-align: middle;">
  <br><br>
  <button id="startBtn" style="
      background-color: #007bff;
      color: white;
      border: none;
      border-radius: 5px;
      padding: 10px 20px;
      font-size: 16px;
      cursor: pointer;
      box-shadow: 0px 3px 6px rgba(0,0,0,0.16);
      margin: 5px;
  ">Run Gradient Descent</button>
  <button id="stopBtn" style="
      background-color: #e74c3c;
      color: white;
      border: none;
      border-radius: 5px;
      padding: 10px 20px;
      font-size: 16px;
      cursor: pointer;
      box-shadow: 0px 3px 6px rgba(0,0,0,0.16);
      margin: 5px;
  ">Stop</button>
  <button id="resetBtn" style="
      background-color: #95a5a6;
      color: white;
      border: none;
      border-radius: 5px;
      padding: 10px 20px;
      font-size: 16px;
      cursor: pointer;
      box-shadow: 0px 3px 6px rgba(0,0,0,0.16);
      margin: 5px;
  ">Reset</button>
  <div id="stepCounter" style="font-size:16px; margin-top:10px;">Steps: 0</div>
  <div id="errorCounter" style="font-size:16px; margin-top:10px;">Error Rate: 0</div>
  <div id="infoPanel" style="font-size:16px; margin-top:10px;">
    Current parameter: \\(\\beta_{\\text{current}} = ?\\)<br>
    Error: \\(E = ?\\)
  </div>
</div>
        <div class="vocab-section">
            <h3>Build Your Vocab</h3>
            <h4 class="vocab-term">Learning Rate (\(\alpha\))</h4>
            <p>A hyperparameter that controls the step size taken in each iteration of Gradient Descent. It determines how quickly or slowly the algorithm learns.</p>
        </div>
        <p>And that's the essence of Gradient Descent! It's a simple yet powerful way to find the parameters that minimize our cost function and make our Machine Learning models learn.</p>
        <div class="continue-button" onclick="showNextSection(16)">Continue</div>
    </section>

    <section id="section16">
        <div class="why-it-matters">
            <h3>Why It Matters</h3>
            <p>Gradient Descent is a cornerstone algorithm in Machine Learning because it provides a practical way to train a wide variety of models, especially when dealing with large datasets and complex cost functions. It's the engine that powers many Machine Learning applications you use every day!</p>
        </div>
        <div class="continue-button" onclick="showNextSection(17)">Continue</div>
    </section>

    <section id="section17">
        <div class="stop-and-think">
            <h3>Stop and Think</h3>
            <h4>Imagine you are tuning a radio to get the clearest signal. Think about how you adjust the dial. How is this similar to or different from Gradient Descent? Share your thoughts in the discussion forum!</h4>
            <button class="reveal-button" onclick="revealAnswer('stop-and-think-1')">Reveal</button>
            <p id="stop-and-think-1" style="display: none;">In radio tuning, you might adjust the dial slightly and check if the signal gets better or worse. If it gets better, you continue in that direction; if worse, you reverse direction. This trial-and-error process is similar in spirit to Gradient Descent's iterative steps, although Gradient Descent is more systematic and uses the gradient to guide its steps more precisely.</p>
        </div>
        <div class="continue-button" onclick="showNextSection(18)">Continue</div>
    </section>

    <section id="section18">
        <div class="faq-section">
            <h3>Frequently Asked Questions</h3>
            <h4>Is Gradient Descent always guaranteed to find the absolute best solution?</h4>
            <p>Not always. For complex cost functions (which we'll discuss later), Gradient Descent might get stuck in a 'good enough' but not perfect solution. However, in many cases, and especially with well-designed cost functions, it gets us very close to the optimal solution, which is often sufficient for practical purposes.</p>
        </div>
        <div class="continue-button" onclick="showNextSection(19)">Continue</div>
    </section>

    <section id="section19">
        <div class="test-your-knowledge">
            <h3>Test Your Knowledge</h3>
            <h4>Which of the following is NOT a key component of the Gradient Descent algorithm?</h4>
            <div id="quiz-options">
                <button class="check-button" onclick="checkAnswer(0)">Cost Function</button>
                <button class="check-button" onclick="checkAnswer(1)">Parameters</button>
                <button class="check-button" onclick="checkAnswer(2)">Learning Rate</button>
                <button class="check-button" onclick="checkAnswer(3)">Dataset Size</button>
            </div>
            <p id="quiz-feedback" style="display: none;"></p>
        </div>
        <div class="continue-button" onclick="showNextSection(20)">Continue</div>
    </section>

    <section id="section20">
        <p>Congratulations on completing Lesson 1! You now have a solid understanding of the fundamental idea behind Gradient Descent. In the next lesson, we'll dive deeper into the 'cost function' and 'gradients' themselves, and see how we can actually calculate them for a specific type of Machine Learning problem: Linear Regression. Get ready to get a bit more mathematical!</p>
    </section>

    <script>
        // Show the first section initially
        document.getElementById("section1").style.display = "block";
        document.getElementById("section1").style.opacity = "1";

        function showNextSection(nextSectionId) {
            const currentButton = event.target;
            const nextSection = document.getElementById("section" + nextSectionId);
            
            currentButton.style.display = "none";
            
            nextSection.style.display = "block";
            setTimeout(() => {
                nextSection.style.opacity = "1";
            }, 10);

            setTimeout(() => {
                nextSection.scrollIntoView({ behavior: 'smooth', block: 'start' });
            }, 500);
        }

        function revealAnswer(id) {
            const revealText = document.getElementById(id);
            const revealButton = event.target;
            
            revealText.style.display = "block";
            revealButton.style.display = "none";
        }

        function checkAnswer(index) {
            const feedback = document.getElementById("quiz-feedback");
            const options = [
                "The cost function is essential! It's what Gradient Descent aims to minimize.",
                "Parameters are what we adjust to minimize the cost function.",
                "The learning rate controls the step size, a crucial part of Gradient Descent.",
                "Correct! While dataset size indirectly affects how we might use Gradient Descent (e.g., choosing between Batch GD or SGD later), it's not a component of the core algorithm itself. The core algorithm works with gradients calculated from the cost function, regardless of dataset size."
            ];
            feedback.textContent = options[index];
            feedback.style.display = "block";
        }
// Get references to HTML elements
  const canvas = document.getElementById('gdCanvas');
  const ctx = canvas.getContext('2d');
  const lrSlider = document.getElementById('lrSlider');
  const lrValueDisplay = document.getElementById('lrValue');
  const startBtn = document.getElementById('startBtn');
  const stopBtn = document.getElementById('stopBtn');
  const resetBtn = document.getElementById('resetBtn');
  const stepCounter = document.getElementById('stepCounter');
  const errorCounter = document.getElementById('errorCounter');
  const infoPanel = document.getElementById('infoPanel');

  // Learning rate handling
  let learningRate = parseFloat(lrSlider.value);
  lrSlider.addEventListener('input', function() {
    learningRate = parseFloat(lrSlider.value);
    lrValueDisplay.textContent = learningRate;
  });

  // Define the original cost function:
  // f(x) = 50 + ((x - 300)^2)/300, which has a minimum of 50 at x = 300.
  function costFunction(x) {
    return 50 + ((x - 300) * (x - 300)) / 300;
  }

  // Transform the cost function so that the minimum appears at the bottom.
  // yPos(x) = canvas.height - (f(x) - 50)
  function yPos(x) {
    return canvas.height - (costFunction(x) - 50);
  }

  // The gradient of the cost function: f'(x) = (x - 300)/150.
  function gradient(x) {
    return (x - 300) / 150;
  }

  // Draw the transformed (upside-down) cost function.
  function drawCostFunction() {
    ctx.clearRect(0, 0, canvas.width, canvas.height);
    ctx.beginPath();
    for (let x = 0; x <= canvas.width; x++) {
      const y = yPos(x);
      if (x === 0) {
        ctx.moveTo(x, y);
      } else {
        ctx.lineTo(x, y);
      }
    }
    ctx.strokeStyle = "#4a90e2"; // clean blue color
    ctx.lineWidth = 3;
    ctx.stroke();
  }

  // Draw a point on the curve with a label (drawn on the canvas as well).
  function drawPoint(x, label, color = '#e74c3c') {
    const y = yPos(x);
    ctx.beginPath();
    ctx.arc(x, y, 6, 0, Math.PI * 2);
    ctx.fillStyle = color;
    ctx.fill();
    ctx.font = "16px Arial";
    ctx.fillStyle = "black";
    ctx.fillText(label, x + 10, y - 10);
  }

  // Draw an arrow from (x1, y1) to (x2, y2) to indicate a gradient descent step.
  // The arrowhead size is set smaller (headlen = 7).
  function drawArrow(x1, y1, x2, y2, color = '#27ae60') {
    const headlen = 7; // length of arrow head
    const dx = x2 - x1;
    const dy = y2 - y1;
    const angle = Math.atan2(dy, dx);
    
    // Draw the line
    ctx.beginPath();
    ctx.moveTo(x1, y1);
    ctx.lineTo(x2, y2);
    ctx.strokeStyle = color;
    ctx.lineWidth = 2;
    ctx.stroke();

    // Draw the arrow head
    ctx.beginPath();
    ctx.moveTo(x2, y2);
    ctx.lineTo(x2 - headlen * Math.cos(angle - Math.PI / 6),
               y2 - headlen * Math.sin(angle - Math.PI / 6));
    ctx.lineTo(x2 - headlen * Math.cos(angle + Math.PI / 6),
               y2 - headlen * Math.sin(angle + Math.PI / 6));
    ctx.lineTo(x2, y2);
    ctx.fillStyle = color;
    ctx.fill();
  }

  let startingX = null; // User-selected starting point (β_start)
  let currentX = null;
  let animationFrameId = null;
  let iterations = 0;

  // Allow the user to click on the canvas to set the starting point.
  canvas.addEventListener('click', function(event) {
    // Only allow setting the starting point if an animation is not running.
    if (animationFrameId) return;
    const rect = canvas.getBoundingClientRect();
    const x = event.clientX - rect.left;
    startingX = x;
    drawCostFunction();
    drawPoint(startingX, "β_start", '#e74c3c');
    // Reset the counters and info panel
    iterations = 0;
    stepCounter.textContent = "Steps: " + iterations;
    errorCounter.textContent = "Error Rate: 0";
    infoPanel.innerHTML = "Current parameter: \\(\\beta_{\\text{current}} = " + startingX.toFixed(2) + "\\)<br>Error: \\(E = " + (costFunction(startingX) - 50).toFixed(2) + "\\)";
    MathJax.typesetPromise();
  });

  // Animate the Gradient Descent process until convergence.
  function runGradientDescent() {
    drawCostFunction();
    // Use the user-selected starting point if available; otherwise, choose a random one.
    currentX = (startingX !== null) ? startingX : Math.floor(Math.random() * canvas.width);
    drawPoint(currentX, "β_start", '#e74c3c');

    let path = [{ x: currentX, y: yPos(currentX) }];
    iterations = 0;
    stepCounter.textContent = "Steps: " + iterations;

    function step() {
      iterations++;
      stepCounter.textContent = "Steps: " + iterations;
      
      const grad = gradient(currentX);
      const newX = currentX - learningRate * grad;

      // Draw an arrow to show this gradient descent step.
      drawArrow(currentX, yPos(currentX), newX, yPos(newX), '#27ae60');

      currentX = newX;
      path.push({ x: currentX, y: yPos(currentX) });

      // Redraw the cost function and the descent path.
      drawCostFunction();
      ctx.beginPath();
      ctx.moveTo(path[0].x, path[0].y);
      for (let i = 1; i < path.length; i++) {
        ctx.lineTo(path[i].x, path[i].y);
      }
      ctx.strokeStyle = "#f39c12"; // orange path line
      ctx.lineWidth = 2;
      ctx.stroke();

      // Mark the current point.
      drawPoint(currentX, "β_current", '#e74c3c');

      // Compute error as the difference from the minimum cost.
      const error = costFunction(currentX) - 50;
      errorCounter.textContent = "Error Rate: " + error.toFixed(2);
      
      // Update the LaTeX info panel.
      infoPanel.innerHTML = "Current parameter: \\(\\beta_{\\text{current}} = " + currentX.toFixed(2) + "\\)<br>Error: \\(E = " + error.toFixed(2) + "\\)";
      MathJax.typesetPromise();

      // Continue iterating until convergence (gradient nearly zero)
      // or a maximum iteration count is reached.
      if (Math.abs(grad) < 0.001 || iterations > 1000) {
        drawPoint(currentX, "β_{learned}", '#8e44ad'); // final point in purple
        animationFrameId = null;
      } else {
        animationFrameId = requestAnimationFrame(step);
      }
    }
    animationFrameId = requestAnimationFrame(step);
  }

  // Stop button: Cancel the animation if it's running.
  stopBtn.addEventListener('click', function() {
    if (animationFrameId) {
      cancelAnimationFrame(animationFrameId);
      animationFrameId = null;
    }
  });

  // Reset button: Cancel any running animation and reset the interactive.
  resetBtn.addEventListener('click', function() {
    if (animationFrameId) {
      cancelAnimationFrame(animationFrameId);
      animationFrameId = null;
    }
    startingX = null;
    currentX = null;
    iterations = 0;
    stepCounter.textContent = "Steps: " + iterations;
    errorCounter.textContent = "Error Rate: 0";
    infoPanel.innerHTML = "Current parameter: \\(\\beta_{\\text{current}} = ?\\)<br>Error: \\(E = ?\\)";
    drawCostFunction();
    MathJax.typesetPromise();
  });

  // Start the gradient descent animation when the "Run" button is clicked.
  startBtn.addEventListener('click', function() {
    runGradientDescent();
  });

  // Draw the initial cost function on page load.
  drawCostFunction();
    </script>
</body>
</html>
